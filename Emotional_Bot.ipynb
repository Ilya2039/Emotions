{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4tbSEQ8VzMm3"
      },
      "outputs": [],
      "source": [
        "# Загружаем необоходимые пакеты"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-telegram-bot==13.13\n",
        "!pip install SpeechRecognition\n",
        "!pip install pydub\n",
        "!pip install deepface\n",
        "!pip install openai\n",
        "!pip install text_hammer\n",
        "!pip install transformers\n",
        "!pip install translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y-TdE_XDzaFu",
        "outputId": "1504a9fa-da7f-436a-9d27-2fbaf398c5c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-telegram-bot==13.13\n",
            "  Downloading python_telegram_bot-13.13-py3-none-any.whl (513 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.4/513.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.13) (2022.12.7)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.13) (6.3.1)\n",
            "Collecting APScheduler==3.6.3 (from python-telegram-bot==13.13)\n",
            "  Downloading APScheduler-3.6.3-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.10/dist-packages (from python-telegram-bot==13.13) (2022.7.1)\n",
            "Collecting cachetools==4.2.2 (from python-telegram-bot==13.13)\n",
            "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.13) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.13) (1.16.0)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from APScheduler==3.6.3->python-telegram-bot==13.13) (4.3)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal>=1.2->APScheduler==3.6.3->python-telegram-bot==13.13) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal>=1.2->APScheduler==3.6.3->python-telegram-bot==13.13) (2023.3)\n",
            "Installing collected packages: cachetools, APScheduler, python-telegram-bot\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.3.0\n",
            "    Uninstalling cachetools-5.3.0:\n",
            "      Successfully uninstalled cachetools-5.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed APScheduler-3.6.3 cachetools-4.2.2 python-telegram-bot-13.13\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepface\n",
            "  Downloading deepface-0.0.79-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.24.3)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.65.0)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.6.6)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (8.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.7.0.72)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.12.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.12.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.4)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.13-py3-none-any.whl (16 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.3.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.11.2)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2022.7.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.3.25)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (16.0.0)\n",
            "Collecting numpy>=1.14.0 (from deepface)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.20.3)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=1.9.0->deepface) (1.10.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.1.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (1.8.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=1.9.0->deepface) (3.2.2)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=1a561a4e16b1690784d21f43ca8b441fdd1d305a9052797fefec76f07b6a2c8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: numpy, gunicorn, fire, mtcnn, retina-face, deepface\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.3\n",
            "    Uninstalling numpy-1.24.3:\n",
            "      Successfully uninstalled numpy-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.25 which is incompatible.\n",
            "flax 0.6.9 requires jax>=0.4.2, but you have jax 0.3.25 which is incompatible.\n",
            "orbax-checkpoint 0.2.1 requires jax>=0.4.8, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deepface-0.0.79 fire-0.5.0 gunicorn-20.1.0 mtcnn-0.1.1 numpy-1.23.5 retina-face-0.0.13\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting text_hammer\n",
            "  Downloading text_hammer-0.1.5-py3-none-any.whl (7.6 kB)\n",
            "Collecting beautifulsoup4==4.9.1 (from text_hammer)\n",
            "  Downloading beautifulsoup4-4.9.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from text_hammer) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from text_hammer) (1.23.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from text_hammer) (3.5.2)\n",
            "Requirement already satisfied: TextBlob in /usr/local/lib/python3.10/dist-packages (from text_hammer) (0.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.9.1->text_hammer) (2.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->text_hammer) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->text_hammer) (2022.7.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->text_hammer) (3.3.0)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from TextBlob->text_hammer) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->TextBlob->text_hammer) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->TextBlob->text_hammer) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->TextBlob->text_hammer) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy->text_hammer) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->text_hammer) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->text_hammer) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->text_hammer) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->text_hammer) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->text_hammer) (2.1.2)\n",
            "Installing collected packages: beautifulsoup4, text_hammer\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.2\n",
            "    Uninstalling beautifulsoup4-4.11.2:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yfinance 0.2.18 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beautifulsoup4-4.9.1 text_hammer-0.1.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting translate\n",
            "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from translate) (8.1.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from translate) (4.9.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from translate) (2.27.1)\n",
            "Collecting libretranslatepy==2.1.1 (from translate)\n",
            "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->translate) (3.4)\n",
            "Installing collected packages: libretranslatepy, translate\n",
            "Successfully installed libretranslatepy-2.1.1 translate-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Код телеграм бота"
      ],
      "metadata": {
        "id": "5mZYRtTtzpuO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from telegram.ext import Updater, MessageHandler, Filters\n",
        "from telegram.ext import CommandHandler\n",
        "from deepface import DeepFace\n",
        "\n",
        "from telegram import InlineKeyboardButton, InlineKeyboardMarkup\n",
        "from telegram.ext import Updater, CommandHandler, CallbackQueryHandler\n",
        "\n",
        "from telegram import ReplyKeyboardMarkup, KeyboardButton\n",
        "\n",
        "from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup\n",
        "from telegram.ext import Updater, CommandHandler, CallbackQueryHandler, MessageHandler, Filters, CallbackContext\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "# from moviepy.editor import VideoFileClip\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "from telegram import Bot, ChatAction\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    #for filename in filenames:\n",
        "        #print(os.path.join(dirname, filename))\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "from tensorflow.keras.applications import VGG16, InceptionResNetV2\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\n",
        "from keras.layers import Dense\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import text_hammer as th\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer,TFBertModel\n",
        "from transformers import BertTokenizer, TFBertModel, BertConfig,TFDistilBertModel,DistilBertTokenizer,DistilBertConfig\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%config Completer.use_jedi = False # if autocompletion doesnot work in kaggle notebook | hit tab\n",
        "\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils\n",
        "\n",
        "from translate import Translator\n",
        "\n",
        "import os\n",
        "import openai as ai\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Загружаем модель по распознаванию эмоций с фото\n",
        "from tensorflow.keras.models import load_model\n",
        "model_photo = load_model('/content/drive/MyDrive/model_happy.h5')\n",
        "\n",
        "# Загружаем модель для распознавания эмоций с текста\n",
        "from tensorflow.keras.models import load_model\n",
        "model = keras.models.load_model('/content/drive/MyDrive/model_text.h5', custom_objects={'TFBertModel': TFBertModel})\n",
        "\n",
        "#---------------------------------------------------------------------------#\n",
        "\n",
        "# Для обработки аудио\n",
        "def convert_ogg_to_wav(filename):\n",
        "    audio = AudioSegment.from_ogg(filename)\n",
        "    wav_filename = filename.replace('.ogg', '.wav')\n",
        "    audio.export(wav_filename, format='wav')\n",
        "    return wav_filename\n",
        "\n",
        "# Функция для распознавания речи из wav файла\n",
        "def audio_to_text(filename):\n",
        "    r = sr.Recognizer()\n",
        "\n",
        "    with sr.AudioFile(filename) as source:\n",
        "        audio_data = r.record(source)\n",
        "        text = r.recognize_google(audio_data, language='ru-RU')\n",
        "        return text\n",
        "\n",
        "\n",
        "# Превращаем видео в набор фото\n",
        "def extract_frames(video_path, output_folder, num_frames):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    if num_frames > total_frames:\n",
        "        print(f\"Запрошено больше кадров, чем доступно. Извлечение всех {total_frames} кадров.\")\n",
        "        num_frames = total_frames\n",
        "\n",
        "    frames_to_extract = sorted(set([int(i * total_frames / num_frames) for i in range(num_frames+1)]))\n",
        "\n",
        "    current_frame = 0\n",
        "    extracted_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if current_frame in frames_to_extract:\n",
        "            save_path = os.path.join(output_folder, f\"frame{current_frame}.jpg\")\n",
        "            cv2.imwrite(save_path, frame)\n",
        "            extracted_count += 1\n",
        "\n",
        "        current_frame += 1\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(f\"Извлечено {extracted_count} кадров и сохранено в папке {output_folder}\")\n",
        "\n",
        "# Узнаем эмоцию на каждой фотки и выдаем результат\n",
        "def find_emotion():\n",
        "  # Укажите путь к папке с файлами\n",
        "    folder_path = '/content/drive/MyDrive/VideoPhragments'\n",
        "\n",
        "# Получаем список всех файлов в папке\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    list_emotions = []\n",
        "\n",
        "# Проходимся по каждому файлу\n",
        "    for file in files:\n",
        "    # Получаем полный путь файла\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "    \n",
        "    # Проверяем, является ли файл изображением\n",
        "        if file.endswith('.jpg') or file.endswith('.jpeg') or file.endswith('.png'):\n",
        "        # Открываем изображение\n",
        "            img = Image.open(file_path)\n",
        "        # Выводим изображение на экран\n",
        "\n",
        "\n",
        "        # Загружаем предварительно обученный каскад Хаара\n",
        "            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "        # Загружаем изображение\n",
        "            img = cv2.imread(file_path)\n",
        "\n",
        "        # Преобразуем изображение в черно-белое\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Обнаруживаем лица\n",
        "            faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "            if len(faces) > 0:\n",
        "            \n",
        "                try:\n",
        "                    result = DeepFace.analyze(img_path = file_path, actions=['age', 'gender', 'race', 'emotion'])\n",
        "                    \n",
        "                except ValueError:\n",
        "                    print(\"Division by zero error occurred\")\n",
        "\n",
        "\n",
        "            #print(result)\n",
        "                result = str(result)\n",
        "                print(result)\n",
        "                emotion = result[result.find('dominant_emotion') + 20:len(result) - 3]\n",
        "                print(emotion)\n",
        "                list_emotions.append(emotion)\n",
        "        os.remove(os.path.join(folder_path, file))\n",
        "        time.sleep(5)\n",
        "\n",
        "    # print(list_emotions) \n",
        "    # print(max(list_emotions))\n",
        "\n",
        "    counter = 0\n",
        "    num = result[0]\n",
        "     \n",
        "    for i in list_emotions:\n",
        "        curr_frequency = list_emotions.count(i)\n",
        "        if(curr_frequency> counter):\n",
        "            counter = curr_frequency\n",
        "            num = i\n",
        "    return num \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def start(update, context):\n",
        "    update.message.reply_text('Привет! Я бот психолог, которому не нужно платить по 10 тысяч за сеанс')\n",
        "    time.sleep(4)\n",
        "    update.message.reply_text('Выбирай с чем будем работать')\n",
        "    keyboard = [\n",
        "        [\n",
        "            InlineKeyboardButton(\"Фото\", callback_data='button1'),\n",
        "            InlineKeyboardButton(\"Видео\", callback_data='button2'),\n",
        "            InlineKeyboardButton(\"Аудио\", callback_data='button3'),\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
        "\n",
        "    update.message.reply_text('Где будем распознавать эмоцию?', reply_markup=reply_markup)\n",
        "    print(1)\n",
        "\n",
        "\n",
        "# создаем обработчик кнопок\n",
        "def button(update: Update, context: CallbackContext) -> None:\n",
        "    query = update.callback_query\n",
        "    query.answer()\n",
        "\n",
        "    if query.data == 'button1':\n",
        "        query.edit_message_text(text=\"Отправь мне фото и я выдам тебе эмоцию\")\n",
        "    elif query.data == 'button2':\n",
        "        query.edit_message_text(text=\"Отправь мне видео и я выдам тебе эмоцию\")\n",
        "    elif query.data == 'button3':\n",
        "        query.edit_message_text(text=\"Отправь мне аудио и я выдам тебе эмоцию\")\n",
        "    elif query.data == 'button4':\n",
        "        query.edit_message_text(text=\"Опиши мне почему человек на фото испытывает такую эмоцию и я скажу что можно сделать\")\n",
        "    elif query.data == 'button5':\n",
        "        query.edit_message_text(text=\"Введи команду /start и начни заново\")\n",
        "\n",
        "def handle_audio(update, context):\n",
        "    file = context.bot.getFile(update.message.voice.file_id)\n",
        "    ogg_file = 'audio.ogg'\n",
        "    file.download(ogg_file)\n",
        "\n",
        "    wav_file = convert_ogg_to_wav(ogg_file)\n",
        "    \n",
        "    # текст голоса, полученный от пользователя\n",
        "    text = audio_to_text(wav_file)\n",
        "\n",
        "    update.message.reply_text('Проверь, что я правильно расшифровал твою речь. Если ты говорил немного другое, отправь мне более разборчивое аудио')\n",
        "\n",
        "\n",
        "    update.message.reply_text(f\"Твой текст: {text}\")\n",
        "\n",
        "    # Перевод текста с русского на английский\n",
        "    translator = Translator(from_lang = \"ru\", to_lang = \"en\")\n",
        "    translation = translator.translate(text)\n",
        "    text = translation\n",
        "\n",
        "    # update.message.reply_text(f\"Твой текст: {text}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "    bert = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "    max_len = 70\n",
        "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "\n",
        "    x_val = tokenizer(\n",
        "        text=text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=70,\n",
        "        truncation=True,\n",
        "        padding='max_length', \n",
        "        return_tensors='tf',\n",
        "        return_token_type_ids = True,\n",
        "        return_attention_mask = True,\n",
        "        verbose = True\n",
        "    ) \n",
        "    \n",
        "    validation = model.predict({'input_ids':x_val['input_ids'], 'token_type_ids':x_val['token_type_ids'], 'attention_mask':x_val['attention_mask']})*100\n",
        "\n",
        "    encoded_dict  = {'sad':0,'joy':1, 'love':2, 'anger':3, 'fear':4}\n",
        "\n",
        "    max_value = 0\n",
        "    max_key = 0\n",
        "    for key , value in zip(encoded_dict.keys(),validation[0]):\n",
        "        if value > max_value:\n",
        "            max_value = value\n",
        "            max_key = key\n",
        "        \n",
        "        print(key,value)\n",
        "\n",
        "    if max_key == 'joy' or max_key == 'love':\n",
        "        update.message.reply_text(f\" Твое аудиосообщение говорит мне о том, что ты счастлив или весел в данный момент\")\n",
        "    elif max_key == 'anger':\n",
        "        update.message.reply_text(f\"Твое аудиосообщение говорит мне о том, что ты очень зол в данный момент\")\n",
        "    if max_key == 'sad' or max_key == 'fear':\n",
        "        update.message.reply_text(f\"Твое аудиосообщение говорит мне о том, что тебе грустно или немного страшно в данный момент\")\n",
        "\n",
        "    # remove audio files after processing\n",
        "    os.remove(ogg_file)\n",
        "    os.remove(wav_file)\n",
        "\n",
        "    # context.bot.send_message(chat_id=update.effective_chat.id, text=text)   \n",
        "\n",
        "\n",
        "# Запрос к гпт боту\n",
        "def echo(update, context):\n",
        "    print(1)\n",
        "    text = update.message.text\n",
        "    print(1)\n",
        "    ai.api_key = \"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\"\n",
        "    completions = ai.Completion.create(\n",
        "        engine='text-davinci-003',  # Determines the quality, speed, and cost.\n",
        "        temperature=0.5,            # Level of creativity in the response\n",
        "        prompt=text,           # What the user typed in\n",
        "        max_tokens=1000,             # Maximum tokens in the prompt AND response\n",
        "        n=1,                        # The number of completions to generate\n",
        "        stop=None,                  # An optional setting to control response generation\n",
        "    )\n",
        "    # text = update.message.text\n",
        "    # response = generate_gpt3_response(text) # вызов другой функции для обработки сообщения пользователя\n",
        "    context.bot.send_message(chat_id=update.effective_chat.id, text=completions.choices[0].text)\n",
        "\n",
        "# Анализ видео\n",
        "def emotions_video(update, context):\n",
        "    update.message.reply_text('Обрабатываем ваш запрос, немного подождите')\n",
        "    print(1)\n",
        "    \"\"\"Save the video file.\"\"\"\n",
        "    video_file = context.bot.getFile(update.message.video.file_id)\n",
        "    video_file.download('/content/drive/MyDrive/Videos/video.mp4')\n",
        "    # file.download('video.mp4')\n",
        "    # update.message.reply_text('Video saved.')\n",
        "    video_path = \"/content/drive/MyDrive/Videos/video.mp4\" #\"videoMisha.mp4\"\n",
        "    output_folder = '/content/drive/MyDrive/VideoPhragments'\n",
        "    clip = VideoFileClip(video_path)\n",
        "    num_frames = int(clip.duration)\n",
        "    print(1)\n",
        "    extract_frames(video_path, output_folder, num_frames)\n",
        "    \n",
        "\n",
        "\n",
        "    time.sleep(20)\n",
        "\n",
        "    s = find_emotion()\n",
        "\n",
        "    update.message.reply_text(f\"Эмоция человека на видео: {s}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Анализ фото\n",
        "def handle_image(update, context):\n",
        "    \"\"\"Ответ на отправку картинки.\"\"\"\n",
        "    # получаем первую фотографию из сообщения пользователя\n",
        "    photo = update.message.photo[-1].get_file()\n",
        "    # сохраняем фото на диск\n",
        "    photo_path = 'image.jpg'\n",
        "    photo.download(photo_path)\n",
        "\n",
        "    update.message.reply_text('Ожидайте...')\n",
        "    # используем модель для определения эмоции на фото\n",
        "    result = DeepFace.analyze(photo_path, actions=['age', 'gender', 'race', 'emotion'])\n",
        "\n",
        "    result = str(result)\n",
        "    \n",
        "    # отправляем результат пользователю\n",
        "    update.message.reply_text(f\"Примерный возраст человека на фото: {result[int(result.find('age')) + 6: int(result.find('region')) - 3]}\")\n",
        "\n",
        "    if result[result.find('dominant_gender') + 19: int(result.find('race')) - 4] == 'Man':\n",
        "        update.message.reply_text(f\"На фото: {'мужчина'}\")  \n",
        "    else:\n",
        "        update.message.reply_text(f\"На фото: {'женщина'}\")  \n",
        "\n",
        "    # update.message.reply_text(f\"Пол человека на фото: {result[result.find('dominant_gender') + 19: int(result.find('race')) - 4]}\")\n",
        "    # update.message.reply_text(f\"Раса человека на фото: {result[result.find('dominant_race') + 17:int(result.find('emotion')) - 4]}\")\n",
        "\n",
        "    # update.message.reply_text(f\"Эмоция человека на фото: {result[result.find('dominant_emotion') + 20:len(result) - 3]}\")\n",
        "\n",
        "    # Предсказание модели\n",
        "    img = tf.keras.utils.load_img(photo_path, target_size = (48,48),color_mode = \"grayscale\")\n",
        "    img = np.array(img)\n",
        "    img = np.expand_dims(img,axis = 0) #makes image shape (1,48,48)\n",
        "    img = img.reshape(1,48,48,1)\n",
        "    result = model_photo.predict(img)\n",
        "    result = list(result[0])\n",
        "    label_dict = {0:'Angry',1:'Happy',2:'Sad'}\n",
        "    img_index = result.index(max(result))\n",
        "    print(label_dict[img_index])\n",
        "\n",
        "    if label_dict[img_index] == 'Angry':\n",
        "        update.message.reply_text(f\"Человек на фото испытывает злость\")\n",
        "    elif label_dict[img_index] == 'Happy':\n",
        "        update.message.reply_text(f\"Человек на фото испытывает радость\")\n",
        "    else:\n",
        "        update.message.reply_text(f\"Человек на фото испытывает грусть или страх\")\n",
        "        \n",
        "\n",
        "    # update.message.reply_text(f\"Эмоция человека на фото: {label_dict[img_index]}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    time.sleep(4)\n",
        "\n",
        "    # update.message.reply_text(\"Хочешь ли ты услышать мой совет по поводу как улучшить твое настроение?\")\n",
        "    # update.message.reply_text(\"Задай вопросу гпт боту\")\n",
        "    # update.message.reply_text('Приветствую тебя в боте, который определяет эмоции человека')\n",
        "    # update.message.reply_text('Выбирай с чем будем работать')\n",
        "    keyboard = [\n",
        "        [\n",
        "            InlineKeyboardButton(\"Да\", callback_data='button4'),\n",
        "            InlineKeyboardButton(\"Нет, я не доверяю советам ИИ\", callback_data='button5'),           \n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
        "\n",
        "    update.message.reply_text('Хочешь ли ты услышать мой совет по поводу как улучшить настроение человека на фото?', reply_markup=reply_markup)\n",
        "\n",
        "\n",
        "# def debug_message(update, context):\n",
        "   # update.message.reply_text('I received a message.')\n",
        "   # print(update.message)\n",
        "\n",
        "\n",
        "\n",
        "                           \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # updater = Updater(token='6170595803:AAFjT-A1_mHcxlGn-RXDUSYiiov92pwOL64', use_context=True)\n",
        "    updater = Updater('6170595803:AAFjT-A1_mHcxlGn-RXDUSYiiov92pwOL64')\n",
        "\n",
        "    # updater.dispatcher.add_handler(MessageHandler(Filters.all, debug_message))\n",
        "    \n",
        "    # Добавление обработчика видео\n",
        "    updater.dispatcher.add_handler(MessageHandler(Filters.video, emotions_video))\n",
        "\n",
        "    \n",
        "    # Добавление обработчиков команд\n",
        "    updater.dispatcher.add_handler(CommandHandler('start', start))\n",
        "    \n",
        "    # Добавление обработчика текстового сообщения\n",
        "    updater.dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, echo))\n",
        "\n",
        "    #Обработчик кнопок\n",
        "    updater.dispatcher.add_handler(CallbackQueryHandler(button))\n",
        "\n",
        "    # Обработчик аудио\n",
        "    updater.dispatcher.add_handler(MessageHandler(Filters.voice, handle_audio))\n",
        "\n",
        "    # Добавление обработчика отправки картинки\n",
        "    updater.dispatcher.add_handler(MessageHandler(Filters.photo, handle_image))\n",
        "    \n",
        "    updater.start_polling()\n",
        "    updater.idle()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbj0sNUhzsiN",
        "outputId": "0981d5fc-00c3-48d2-9ba9-89d2a9ec26e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "1\n",
            "1\n",
            "1\n",
            "Извлечено 8 кадров и сохранено в папке /content/drive/MyDrive/VideoPhragments\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'age': 29, 'region': {'x': 393, 'y': 137, 'w': 327, 'h': 327}, 'gender': {'Woman': 1.5287133865058422, 'Man': 98.47128391265869}, 'dominant_gender': 'Man', 'race': {'asian': 0.7097453344613314, 'indian': 1.6078464686870575, 'black': 0.3420047927647829, 'white': 60.87642312049866, 'middle eastern': 24.81495589017868, 'latino hispanic': 11.649025231599808}, 'dominant_race': 'white', 'emotion': {'angry': 0.01837645540945232, 'disgust': 1.007418540949212e-10, 'fear': 0.00029710411126870895, 'happy': 46.9237357378006, 'sad': 4.583241377531522e-05, 'surprise': 37.12218105792999, 'neutral': 15.93535840511322}, 'dominant_emotion': 'happy'}]\n",
            "happy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: emotion: 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'age': 27, 'region': {'x': 386, 'y': 128, 'w': 310, 'h': 310}, 'gender': {'Woman': 0.39643109776079655, 'Man': 99.60357546806335}, 'dominant_gender': 'Man', 'race': {'asian': 0.11241710744798183, 'indian': 1.9946649670600891, 'black': 0.061069021467119455, 'white': 40.69806635379791, 'middle eastern': 50.420767068862915, 'latino hispanic': 6.713017821311951}, 'dominant_race': 'middle eastern', 'emotion': {'angry': 0.04964752016112449, 'disgust': 3.447730567926189e-08, 'fear': 0.0010534392805096953, 'happy': 99.66229196337366, 'sad': 0.034620771237144916, 'surprise': 0.00390908145379501, 'neutral': 0.24848180525533023}, 'dominant_emotion': 'happy'}]\n",
            "happy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]\n",
            "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'age': 26, 'region': {'x': 379, 'y': 122, 'w': 310, 'h': 310}, 'gender': {'Woman': 0.881627481430769, 'Man': 99.11837577819824}, 'dominant_gender': 'Man', 'race': {'asian': 0.08862943504936993, 'indian': 3.333018720149994, 'black': 0.02575131948105991, 'white': 30.804869532585144, 'middle eastern': 59.39598083496094, 'latino hispanic': 6.351751089096069}, 'dominant_race': 'middle eastern', 'emotion': {'angry': 0.00043577006181294564, 'disgust': 6.362712579033314e-08, 'fear': 0.0032698844734113663, 'happy': 0.0017110818589571863, 'sad': 97.48247861862183, 'surprise': 2.6456677915120963e-05, 'neutral': 2.512083202600479}, 'dominant_emotion': 'sad'}, {'age': 31, 'region': {'x': 507, 'y': 269, 'w': 69, 'h': 69}, 'gender': {'Woman': 42.325395345687866, 'Man': 57.67461061477661}, 'dominant_gender': 'Man', 'race': {'asian': 7.598932671674172, 'indian': 1.0706218545887645, 'black': 0.16553162486474218, 'white': 72.11022709486161, 'middle eastern': 13.233049126499996, 'latino hispanic': 5.821628174587706}, 'dominant_race': 'white', 'emotion': {'angry': 0.03632841689977795, 'disgust': 0.002397410207777284, 'fear': 1.162175741046667, 'happy': 97.68313765525818, 'sad': 0.46976814046502113, 'surprise': 0.04391808179207146, 'neutral': 0.6022739689797163}, 'dominant_emotion': 'happy'}]\n",
            "sad'}, {'age': 31, 'region': {'x': 507, 'y': 269, 'w': 69, 'h': 69}, 'gender': {'Woman': 42.325395345687866, 'Man': 57.67461061477661}, 'dominant_gender': 'Man', 'race': {'asian': 7.598932671674172, 'indian': 1.0706218545887645, 'black': 0.16553162486474218, 'white': 72.11022709486161, 'middle eastern': 13.233049126499996, 'latino hispanic': 5.821628174587706}, 'dominant_race': 'white', 'emotion': {'angry': 0.03632841689977795, 'disgust': 0.002397410207777284, 'fear': 1.162175741046667, 'happy': 97.68313765525818, 'sad': 0.46976814046502113, 'surprise': 0.04391808179207146, 'neutral': 0.6022739689797163}, 'dominant_emotion': 'happy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: emotion: 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'age': 27, 'region': {'x': 366, 'y': 120, 'w': 334, 'h': 334}, 'gender': {'Woman': 1.4191058464348316, 'Man': 98.58089089393616}, 'dominant_gender': 'Man', 'race': {'asian': 1.4636259467080799, 'indian': 7.7783499824017275, 'black': 0.8874447613921619, 'white': 33.199467253653246, 'middle eastern': 38.734354897401026, 'latino hispanic': 17.93676125626333}, 'dominant_race': 'middle eastern', 'emotion': {'angry': 0.002444548226776533, 'disgust': 1.2084996114936075e-06, 'fear': 0.05967547185719013, 'happy': 38.947632908821106, 'sad': 3.7597209215164185, 'surprise': 0.3437236649915576, 'neutral': 56.88680410385132}, 'dominant_emotion': 'neutral'}]\n",
            "neutral\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]\n",
            "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'age': 27, 'region': {'x': 372, 'y': 115, 'w': 322, 'h': 322}, 'gender': {'Woman': 0.834550429135561, 'Man': 99.16545152664185}, 'dominant_gender': 'Man', 'race': {'asian': 0.07911507855169475, 'indian': 0.9447377175092697, 'black': 0.01779402664396912, 'white': 58.935171365737915, 'middle eastern': 33.46436321735382, 'latino hispanic': 6.558821350336075}, 'dominant_race': 'white', 'emotion': {'angry': 0.019563274112622334, 'disgust': 7.031168521816035e-05, 'fear': 0.04105376918323567, 'happy': 60.69976218935992, 'sad': 34.40900259125264, 'surprise': 0.046075554236463215, 'neutral': 4.78447434717111}, 'dominant_emotion': 'happy'}, {'age': 30, 'region': {'x': 510, 'y': 272, 'w': 64, 'h': 64}, 'gender': {'Woman': 27.21683979034424, 'Man': 72.78315424919128}, 'dominant_gender': 'Man', 'race': {'asian': 0.8330992919563825, 'indian': 0.3116956399274254, 'black': 0.020875446869552693, 'white': 82.49540820690443, 'middle eastern': 12.644521155626842, 'latino hispanic': 3.694399666452388}, 'dominant_race': 'white', 'emotion': {'angry': 0.000813522916932994, 'disgust': 6.93159532469332e-05, 'fear': 0.8187850050669915, 'happy': 97.63863654597242, 'sad': 0.10625112438587837, 'surprise': 0.021655053968398747, 'neutral': 1.4137927265516192}, 'dominant_emotion': 'happy'}]\n",
            "happy'}, {'age': 30, 'region': {'x': 510, 'y': 272, 'w': 64, 'h': 64}, 'gender': {'Woman': 27.21683979034424, 'Man': 72.78315424919128}, 'dominant_gender': 'Man', 'race': {'asian': 0.8330992919563825, 'indian': 0.3116956399274254, 'black': 0.020875446869552693, 'white': 82.49540820690443, 'middle eastern': 12.644521155626842, 'latino hispanic': 3.694399666452388}, 'dominant_race': 'white', 'emotion': {'angry': 0.000813522916932994, 'disgust': 6.93159532469332e-05, 'fear': 0.8187850050669915, 'happy': 97.63863654597242, 'sad': 0.10625112438587837, 'surprise': 0.021655053968398747, 'neutral': 1.4137927265516192}, 'dominant_emotion': 'happy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'age': 30, 'region': {'x': 374, 'y': 100, 'w': 345, 'h': 345}, 'gender': {'Woman': 0.2954244613647461, 'Man': 99.70458149909973}, 'dominant_gender': 'Man', 'race': {'asian': 1.3606597669422626, 'indian': 5.8501143008470535, 'black': 3.297557681798935, 'white': 35.91002821922302, 'middle eastern': 36.66912317276001, 'latino hispanic': 16.912518441677094}, 'dominant_race': 'middle eastern', 'emotion': {'angry': 0.00055689438340778, 'disgust': 1.3645890639679692e-06, 'fear': 0.000788267334428383, 'happy': 99.96963739395142, 'sad': 0.009227013651980087, 'surprise': 7.478617902734186e-06, 'neutral': 0.019779872673097998}, 'dominant_emotion': 'happy'}]\n",
            "happy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.96it/s]\n",
            "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'age': 28, 'region': {'x': 371, 'y': 110, 'w': 331, 'h': 331}, 'gender': {'Woman': 0.461222929880023, 'Man': 99.5387852191925}, 'dominant_gender': 'Man', 'race': {'asian': 0.1126550487242639, 'indian': 1.7748942598700523, 'black': 0.03691511519718915, 'white': 46.88882529735565, 'middle eastern': 44.3314403295517, 'latino hispanic': 6.855270266532898}, 'dominant_race': 'white', 'emotion': {'angry': 4.625842979004582e-05, 'disgust': 2.3057470066074062e-11, 'fear': 4.84602735679937e-06, 'happy': 0.014302020759173988, 'sad': 0.1879804776408699, 'surprise': 1.2816567611463915e-06, 'neutral': 99.79766013650178}, 'dominant_emotion': 'neutral'}, {'age': 31, 'region': {'x': 510, 'y': 272, 'w': 64, 'h': 64}, 'gender': {'Woman': 26.298490166664124, 'Man': 73.70151281356812}, 'dominant_gender': 'Man', 'race': {'asian': 12.431249767541885, 'indian': 3.5182777792215347, 'black': 0.4690159112215042, 'white': 48.375529050827026, 'middle eastern': 23.57761114835739, 'latino hispanic': 11.628314852714539}, 'dominant_race': 'white', 'emotion': {'angry': 0.00048028024407475837, 'disgust': 9.527727228322204e-05, 'fear': 0.7667439041130428, 'happy': 37.24678006729842, 'sad': 0.03015508478027848, 'surprise': 0.18868256514088097, 'neutral': 61.76706692779862}, 'dominant_emotion': 'neutral'}]\n",
            "neutral'}, {'age': 31, 'region': {'x': 510, 'y': 272, 'w': 64, 'h': 64}, 'gender': {'Woman': 26.298490166664124, 'Man': 73.70151281356812}, 'dominant_gender': 'Man', 'race': {'asian': 12.431249767541885, 'indian': 3.5182777792215347, 'black': 0.4690159112215042, 'white': 48.375529050827026, 'middle eastern': 23.57761114835739, 'latino hispanic': 11.628314852714539}, 'dominant_race': 'white', 'emotion': {'angry': 0.00048028024407475837, 'disgust': 9.527727228322204e-05, 'fear': 0.7667439041130428, 'happy': 37.24678006729842, 'sad': 0.03015508478027848, 'surprise': 0.18868256514088097, 'neutral': 61.76706692779862}, 'dominant_emotion': 'neutral\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: emotion: 100%|██████████| 4/4 [00:02<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'age': 32, 'region': {'x': 403, 'y': 116, 'w': 333, 'h': 333}, 'gender': {'Woman': 0.11924151331186295, 'Man': 99.88075494766235}, 'dominant_gender': 'Man', 'race': {'asian': 2.0792892202734947, 'indian': 8.096639066934586, 'black': 3.2500948756933212, 'white': 27.8183251619339, 'middle eastern': 41.88509285449982, 'latino hispanic': 16.87055677175522}, 'dominant_race': 'middle eastern', 'emotion': {'angry': 0.00043890611665497206, 'disgust': 3.126315107803335e-12, 'fear': 0.00024155209833257534, 'happy': 1.3604902541929635, 'sad': 0.12038960839150002, 'surprise': 3.83721180830936e-05, 'neutral': 98.51840129604348}, 'dominant_emotion': 'neutral'}]\n",
            "neutral\n"
          ]
        }
      ]
    }
  ]
}